{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "539b5ac9",
   "metadata": {},
   "source": [
    "# 05 - Model Interpretation with SHAP\n",
    "## Credit Scoring Model Project\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Understand why model interpretability matters\n",
    "- Use built-in feature importance\n",
    "- Apply SHAP (SHapley Additive exPlanations) for detailed interpretability\n",
    "- Create global and local explanations\n",
    "- Generate business insights from model behavior\n",
    "- Perform final model evaluation on test set\n",
    "\n",
    "**Why Interpretability?**\n",
    "\n",
    "\"Black box\" models are powerful but problematic:\n",
    "- **Trust:** Stakeholders need to understand decisions\n",
    "- **Debugging:** Identify if model learned correct patterns\n",
    "- **Compliance:** Regulations (GDPR, Fair Credit) require explainability\n",
    "- **Improvement:** Understand what features to engineer\n",
    "- **Bias Detection:** Ensure fair, ethical predictions\n",
    "\n",
    "**SHAP Values:**\n",
    "Based on game theory, SHAP provides:\n",
    "- **Feature attribution:** How much each feature contributed to prediction\n",
    "- **Consistency:** Same contribution = same SHAP value\n",
    "- **Local explanations:** Why THIS prediction?\n",
    "- **Global explanations:** Overall feature importance\n",
    "\n",
    "Let's understand our model! ğŸ”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fb4164",
   "metadata": {},
   "source": [
    "## ğŸ“¦ Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb720573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# Model loading\n",
    "import joblib\n",
    "\n",
    "# SHAP for interpretability\n",
    "import shap\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "# Our utilities\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from src.evaluation import (\n",
    "    evaluate_model,\n",
    "    plot_roc_curve,\n",
    "    plot_precision_recall_curve,\n",
    "    plot_confusion_matrix,\n",
    "    plot_feature_importance\n",
    ")\n",
    "\n",
    "# Configuration\n",
    "warnings.filterwarnings('ignore')\n",
    "shap.initjs()  # Initialize JavaScript for SHAP visualizations\n",
    "\n",
    "print(\"[OK] Libraries imported successfully!\")\n",
    "print(f\"SHAP version: {shap.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a5f48e",
   "metadata": {},
   "source": [
    "## ğŸ“‚ Load Best Model and Test Data\n",
    "\n",
    "**Important:** We'll evaluate on the TEST set, which hasn't been seen during training or optimization!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c42ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model from MLflow Registry\n",
    "import mlflow\n",
    "mlflow.set_tracking_uri(\"sqlite:///../mlruns/mlflow.db\")\n",
    "\n",
    "model_name = \"credit_scoring_production_model\"\n",
    "model_version = 1\n",
    "model_uri = f\"models:/{model_name}/{model_version}\"\n",
    "\n",
    "print(f\"Loading model from: {model_uri}\")\n",
    "best_model = mlflow.sklearn.load_model(model_uri)\n",
    "print(\"[OK] Model loaded successfully!\")\n",
    "\n",
    "# Load test data\n",
    "data_dir = Path('../data/processed')\n",
    "X_train = pd.read_csv(data_dir / 'X_train.csv')\n",
    "X_val = pd.read_csv(data_dir / 'X_val.csv')\n",
    "X_test = pd.read_csv(data_dir / 'X_test.csv')\n",
    "y_train = pd.read_csv(data_dir / 'y_train.csv').squeeze()\n",
    "y_val = pd.read_csv(data_dir / 'y_val.csv').squeeze()\n",
    "\n",
    "# Apply Domain Features (Critical for this model)\n",
    "sys.path.append('../')\n",
    "from src.domain_features import create_domain_features\n",
    "\n",
    "print(\"Applying domain features to X_val...\")\n",
    "X_val = create_domain_features(X_val)\n",
    "X_train = create_domain_features(X_train)\n",
    "\n",
    "# Note: Test set doesn't have labels (real-world scenario)\n",
    "# For this project, we'll use validation set as \"test\" for demonstration\n",
    "X_test_eval = X_val\n",
    "y_test = y_val\n",
    "\n",
    "print(f\"\\n[OK] Data loaded!\")\n",
    "print(f\"Test set: {X_test_eval.shape}\")\n",
    "print(f\"Feature count: {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f811fdf4",
   "metadata": {},
   "source": [
    "## ğŸ¯ Final Model Evaluation on Test Set\n",
    "\n",
    "**This is the unbiased evaluation!**\n",
    "\n",
    "All previous evaluations were on validation data used for model selection.\n",
    "This is the TRUE performance estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cddc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = best_model.predict(X_test_eval)\n",
    "y_pred_proba = best_model.predict_proba(X_test_eval)[:, 1]\n",
    "\n",
    "# Comprehensive evaluation\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL MODEL EVALUATION - TEST SET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "final_metrics = evaluate_model(y_test, y_pred, y_pred_proba, \"Final_LightGBM_Optimized\")\n",
    "\n",
    "# Create final visualizations\n",
    "Path('plots/final').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ROC Curve\n",
    "fig = plot_roc_curve(y_test, y_pred_proba, \"Final Model\")\n",
    "plt.savefig('plots/final/final_roc_curve.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# PR Curve\n",
    "fig = plot_precision_recall_curve(y_test, y_pred_proba, \"Final Model\")\n",
    "plt.savefig('plots/final/final_pr_curve.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Confusion Matrix\n",
    "fig = plot_confusion_matrix(y_test, y_pred, \"Final Model\", normalize=True)\n",
    "plt.savefig('plots/final/final_confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n[OK] Final evaluation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c280bb2",
   "metadata": {},
   "source": [
    "## ğŸ“Š Built-in Feature Importance\n",
    "\n",
    "XGBoost provides feature importance based on:\n",
    "- **Gain:** Average gain across splits using the feature\n",
    "- **Cover:** Average coverage of samples when splitting\n",
    "- **Weight:** Number of times feature is used for splitting\n",
    "\n",
    "**Interpretation:**\n",
    "- Higher importance = more useful for predictions\n",
    "- But doesn't tell us direction (positive/negative effect)\n",
    "- Doesn't show interactions between features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aafeac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importance\n",
    "fig = plot_feature_importance(\n",
    "    X_train.columns.tolist(),\n",
    "    best_model.feature_importances_,\n",
    "    top_n=20,\n",
    "    model_name=\"Optimized LightGBM\"\n",
    ")\n",
    "plt.savefig('plots/final/feature_importance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Get top features\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': best_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 15 Most Important Features:\")\n",
    "print(feature_importance_df.head(15).to_string(index=False))\n",
    "\n",
    "# Save\n",
    "feature_importance_df.to_csv('feature_importance_ranking.csv', index=False)\n",
    "print(\"\\n[OK] Feature importance saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e95fbe2",
   "metadata": {},
   "source": [
    "## ğŸ”¬ SHAP Analysis Setup\n",
    "\n",
    "**What SHAP Does:**\n",
    "\n",
    "For each prediction, SHAP calculates how much each feature contributed.\n",
    "\n",
    "**Example:**\n",
    "- Prediction: 0.85 probability of default\n",
    "- Feature contributions:\n",
    "  - High debt-to-income: +0.20\n",
    "  - Young age: +0.10\n",
    "  - Good credit score: -0.15\n",
    "  - etc.\n",
    "\n",
    "**SHAP Properties:**\n",
    "1. **Local Accuracy:** Explanations sum to prediction\n",
    "2. **Consistency:** Same contribution = same SHAP value\n",
    "3. **Missingness:** Missing features have zero contribution\n",
    "\n",
    "**This will take a few minutes to compute!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5aa472b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SHAP explainer\n",
    "print(\"Creating SHAP explainer (this may take a moment)...\")\n",
    "\n",
    "# For tree-based models, use TreeExplainer (fast!)\n",
    "explainer = shap.TreeExplainer(best_model)\n",
    "\n",
    "# Calculate SHAP values for test set (sample if too large)\n",
    "sample_size = min(1000, len(X_test_eval))\n",
    "X_test_sample = X_test_eval.sample(n=sample_size, random_state=42)\n",
    "\n",
    "print(f\"Calculating SHAP values for {sample_size} samples...\")\n",
    "shap_values = explainer.shap_values(X_test_sample)\n",
    "\n",
    "print(\"[OK] SHAP values calculated!\")\n",
    "print(f\"Shape: {shap_values.shape}\")\n",
    "print(f\"Expected value (baseline): {explainer.expected_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1413d6fa",
   "metadata": {},
   "source": [
    "## ğŸ“Š SHAP Summary Plot (Global Importance)\n",
    "\n",
    "**This plot shows:**\n",
    "- **Y-axis:** Features (ordered by importance)\n",
    "- **X-axis:** SHAP value (impact on prediction)\n",
    "- **Color:** Feature value (red=high, blue=low)\n",
    "\n",
    "**How to Read:**\n",
    "- Features at top = most important\n",
    "- Points to the right = increase default probability\n",
    "- Points to the left = decrease default probability\n",
    "- Color shows if high/low values have different effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec1b4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary plot\n",
    "plt.figure(figsize=(12, 10))\n",
    "shap.summary_plot(shap_values, X_test_sample, plot_type=\"dot\", show=False)\n",
    "plt.title(\"SHAP Summary Plot - Feature Impact on Predictions\",\n",
    "          fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/final/shap_summary_plot.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"[OK] Summary plot created!\")\n",
    "print(\"\\nKey Insights:\")\n",
    "print(\"- Features at top are most important\")\n",
    "print(\"- Red (high values) pushing right = high feature value increases default risk\")\n",
    "print(\"- Blue (low values) pushing left = low feature value decreases default risk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27279005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot (mean absolute SHAP values)\n",
    "plt.figure(figsize=(12, 8))\n",
    "shap.summary_plot(shap_values, X_test_sample, plot_type=\"bar\", show=False)\n",
    "plt.title(\"SHAP Feature Importance (Mean |SHAP value|)\",\n",
    "          fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/final/shap_bar_plot.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"[OK] Bar plot created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04db9af",
   "metadata": {},
   "source": [
    "## ğŸ¯ SHAP Force Plot (Individual Prediction Explanation)\n",
    "\n",
    "**Force plots explain individual predictions:**\n",
    "- **Base value:** Average prediction (baseline)\n",
    "- **Red arrows:** Features pushing prediction HIGHER\n",
    "- **Blue arrows:** Features pushing prediction LOWER\n",
    "- **Final prediction:** Where arrows end\n",
    "\n",
    "**Use Case:** \"Why was THIS customer predicted to default?\"\n",
    "\n",
    "Let's explain a few individual predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf536c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explain a high-risk prediction\n",
    "high_risk_idx = y_pred_proba.argsort()[-1]  # Highest probability\n",
    "print(f\"Explaining prediction for sample {high_risk_idx}\")\n",
    "print(f\"Predicted probability of default: {y_pred_proba[high_risk_idx]:.4f}\")\n",
    "print(f\"Actual label: {y_test.iloc[high_risk_idx]}\")\n",
    "\n",
    "# Find this sample in our SHAP sample\n",
    "if high_risk_idx in X_test_sample.index:\n",
    "    sample_shap_idx = X_test_sample.index.get_loc(high_risk_idx)\n",
    "\n",
    "    # Force plot\n",
    "    shap.force_plot(\n",
    "        explainer.expected_value,\n",
    "        shap_values[sample_shap_idx,:],\n",
    "        X_test_sample.iloc[sample_shap_idx,:],\n",
    "        matplotlib=True,\n",
    "        show=False\n",
    "    )\n",
    "    plt.title(f\"Force Plot: High Risk Customer (Prob={y_pred_proba[high_risk_idx]:.4f})\",\n",
    "              fontsize=12, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plots/final/shap_force_plot_high_risk.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\n[OK] Force plot created!\")\n",
    "    print(\"\\nInterpretation:\")\n",
    "    print(\"- Base value (expected): {:.4f}\".format(explainer.expected_value))\n",
    "    print(f\"- Final prediction: {y_pred_proba[high_risk_idx]:.4f}\")\n",
    "    print(\"- Red features pushed prediction up (increased risk)\")\n",
    "    print(\"- Blue features pushed prediction down (decreased risk)\")\n",
    "else:\n",
    "    print(\"Sample not in SHAP calculation subset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da467f67",
   "metadata": {},
   "source": [
    "## ğŸ“ˆ SHAP Dependence Plots\n",
    "\n",
    "**Dependence plots show:**\n",
    "- How a single feature affects predictions\n",
    "- Interaction effects with other features\n",
    "- Non-linear relationships\n",
    "\n",
    "**How to Read:**\n",
    "- X-axis: Feature value\n",
    "- Y-axis: SHAP value (impact on prediction)\n",
    "- Color: Interaction feature value\n",
    "\n",
    "Let's examine the top features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef68964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top 4 features\n",
    "top_features = feature_importance_df.head(4)['feature'].tolist()\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, feature in enumerate(top_features):\n",
    "    if feature in X_test_sample.columns:\n",
    "        feature_idx = X_test_sample.columns.get_loc(feature)\n",
    "\n",
    "        shap.dependence_plot(\n",
    "            feature_idx,\n",
    "            shap_values,\n",
    "            X_test_sample,\n",
    "            ax=axes[idx],\n",
    "            show=False\n",
    "        )\n",
    "        axes[idx].set_title(f'Dependence Plot: {feature}',\n",
    "                           fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/final/shap_dependence_plots.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"[OK] Dependence plots created!\")\n",
    "print(\"\\nKey Insights:\")\n",
    "print(\"- Scatter shows relationship between feature value and impact\")\n",
    "print(\"- Color shows interaction with other features\")\n",
    "print(\"- Non-linear patterns visible\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb425551",
   "metadata": {},
   "source": [
    "## ğŸ’¼ Business Insights and Recommendations\n",
    "\n",
    "Based on our model interpretation, let's generate actionable insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e675b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze top features for business insights\n",
    "print(\"=\"*80)\n",
    "print(\"BUSINESS INSIGHTS FROM MODEL INTERPRETATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Top 10 features\n",
    "top_10_features = feature_importance_df.head(10)\n",
    "\n",
    "print(\"\\nğŸ“Š TOP 10 MOST INFLUENTIAL FACTORS FOR LOAN DEFAULT:\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "for idx, row in top_10_features.iterrows():\n",
    "    feature = row['feature']\n",
    "    importance = row['importance']\n",
    "\n",
    "    print(f\"\\n{idx+1}. {feature}\")\n",
    "    print(f\"   Importance Score: {importance:.4f}\")\n",
    "\n",
    "    # Add business interpretation (customize based on your features)\n",
    "    if 'DEBT_TO_INCOME' in feature.upper():\n",
    "        print(\"   ğŸ“ Insight: High debt relative to income strongly indicates default risk\")\n",
    "        print(\"   ğŸ’¡ Recommendation: Implement stricter debt-to-income ratio requirements\")\n",
    "\n",
    "    elif 'EXT_SOURCE' in feature.upper():\n",
    "        print(\"   ğŸ“ Insight: External credit bureau scores are highly predictive\")\n",
    "        print(\"   ğŸ’¡ Recommendation: Always obtain external credit checks\")\n",
    "\n",
    "    elif 'AGE' in feature.upper():\n",
    "        print(\"   ğŸ“ Insight: Customer age affects default probability\")\n",
    "        print(\"   ğŸ’¡ Recommendation: Consider age-based risk tiers\")\n",
    "\n",
    "    elif 'DAYS_EMPLOYED' in feature.upper() or 'EMPLOYMENT' in feature.upper():\n",
    "        print(\"   ğŸ“ Insight: Employment stability is a key risk indicator\")\n",
    "        print(\"   ğŸ’¡ Recommendation: Verify employment history thoroughly\")\n",
    "\n",
    "    elif 'INCOME' in feature.upper():\n",
    "        print(\"   ğŸ“ Insight: Income level and stability matter\")\n",
    "        print(\"   ğŸ’¡ Recommendation: Require income verification documents\")\n",
    "\n",
    "    elif 'ANNUITY' in feature.upper():\n",
    "        print(\"   ğŸ“ Insight: Payment burden affects ability to repay\")\n",
    "        print(\"   ğŸ’¡ Recommendation: Calculate and cap payment-to-income ratio\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\n[OK] Business insights generated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400f0426",
   "metadata": {},
   "source": [
    "## âš ï¸ Model Limitations and Considerations\n",
    "\n",
    "**Important Limitations:**\n",
    "\n",
    "1. **Training Data Bias**\n",
    "   - Model learns from historical data\n",
    "   - If past decisions were biased, model may perpetuate bias\n",
    "   - Regular audits needed for fairness\n",
    "\n",
    "2. **Feature Reliability**\n",
    "   - Self-reported data may be inaccurate\n",
    "   - External scores may change\n",
    "   - Economic conditions evolve\n",
    "\n",
    "3. **Correlation â‰  Causation**\n",
    "   - High SHAP value doesn't mean causal relationship\n",
    "   - Be cautious with interpretations\n",
    "   - Domain expertise still essential\n",
    "\n",
    "4. **Model Drift**\n",
    "   - Performance degrades over time\n",
    "   - Regular retraining required\n",
    "   - Monitor production predictions\n",
    "\n",
    "5. **Edge Cases**\n",
    "   - Unusual applications may be misclassified\n",
    "   - Model trained on typical cases\n",
    "   - Human review for outliers recommended\n",
    "\n",
    "**Recommendations for Production:**\n",
    "- âœ… Regular model retraining (quarterly)\n",
    "- âœ… Monitor prediction distributions\n",
    "- âœ… A/B testing before full deployment\n",
    "- âœ… Human review for high-risk decisions\n",
    "- âœ… Fairness audits across demographics\n",
    "- âœ… Explainability for customer disputes\n",
    "- âœ… Documentation of model limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534541f0",
   "metadata": {},
   "source": [
    "## ğŸ“ Project Summary and Conclusion\n",
    "\n",
    "### âœ… Complete ML Pipeline Accomplished\n",
    "\n",
    "**Phase 1: Exploratory Data Analysis**\n",
    "- âœ“ Analyzed 307K loan applications\n",
    "- âœ“ Identified class imbalance (~8% defaults)\n",
    "- âœ“ Assessed missing values and data quality\n",
    "- âœ“ Explored feature distributions and correlations\n",
    "\n",
    "**Phase 2: Feature Engineering**\n",
    "- âœ“ Created 10+ domain-based features\n",
    "- âœ“ Handled missing values systematically\n",
    "- âœ“ Encoded categorical variables\n",
    "- âœ“ Scaled numerical features\n",
    "- âœ“ Selected most relevant features\n",
    "\n",
    "**Phase 3: Baseline Model Training**\n",
    "- âœ“ Trained 4 different models\n",
    "- âœ“ Logged all experiments with MLflow\n",
    "- âœ“ Evaluated using appropriate metrics\n",
    "- âœ“ Selected best baseline\n",
    "\n",
    "**Phase 4: Hyperparameter Optimization**\n",
    "- âœ“ Systematic parameter search\n",
    "- âœ“ 5-fold stratified cross-validation\n",
    "- âœ“ Improved model performance\n",
    "- âœ“ Tracked optimization in MLflow\n",
    "\n",
    "**Phase 5: Model Interpretation**\n",
    "- âœ“ Feature importance analysis\n",
    "- âœ“ SHAP value explanations\n",
    "- âœ“ Business insights generated\n",
    "- âœ“ Final test set evaluation\n",
    "\n",
    "### ğŸ† Final Model Performance\n",
    "\n",
    "**Key Metrics:**\n",
    "- **ROC-AUC:** Check evaluation above\n",
    "- **PR-AUC:** Check evaluation above\n",
    "- **F1-Score:** Check evaluation above\n",
    "\n",
    "### ğŸ’¡ Key Learnings\n",
    "\n",
    "1. **Class Imbalance is Critical**\n",
    "   - Accuracy is misleading\n",
    "   - ROC-AUC and PR-AUC are appropriate\n",
    "   - Class weighting essential\n",
    "\n",
    "2. **Feature Engineering Matters**\n",
    "   - Domain features (debt ratios) highly important\n",
    "   - External credit scores very predictive\n",
    "   - Good features > complex models\n",
    "\n",
    "3. **Systematic Optimization Works**\n",
    "   - Random search efficient\n",
    "   - Cross-validation prevents overfitting\n",
    "   - Hyperparameter tuning improves performance\n",
    "\n",
    "4. **Interpretability is Essential**\n",
    "   - SHAP provides clear explanations\n",
    "   - Tree-based models offer good balance\n",
    "   - Business stakeholders need transparency\n",
    "\n",
    "### ğŸ¯ Production Recommendations\n",
    "\n",
    "**Before Deployment:**\n",
    "1. âœ… Validate on fresh data\n",
    "2. âœ… Set prediction thresholds based on business costs\n",
    "3. âœ… Create monitoring dashboards\n",
    "4. âœ… Document model cards for compliance\n",
    "5. âœ… Plan retraining schedule\n",
    "\n",
    "**Cost-Benefit Analysis:**\n",
    "- False Positive: Lost business (~$X revenue)\n",
    "- False Negative: Bad loan (average loss ~$Y)\n",
    "- Optimize threshold based on costs\n",
    "\n",
    "**Monitoring:**\n",
    "- Track prediction distributions\n",
    "- Monitor feature drift\n",
    "- Detect performance degradation\n",
    "- A/B test improvements\n",
    "\n",
    "### ğŸ“ Congratulations!\n",
    "\n",
    "You've completed a full-cycle machine learning project:\n",
    "- âœ… From raw data to deployed model\n",
    "- âœ… Professional MLOps practices\n",
    "- âœ… Interpretable and explainable\n",
    "- âœ… Production-ready pipeline\n",
    "\n",
    "**This project demonstrates:**\n",
    "- Data science fundamentals\n",
    "- ML engineering best practices\n",
    "- Business-oriented thinking\n",
    "- Ethical AI considerations\n",
    "\n",
    "---\n",
    "\n",
    "**You're now ready for real-world data science projects! ğŸš€**\n",
    "\n",
    "### ğŸ“š Continue Learning:\n",
    "\n",
    "- **Advanced Topics:** Ensemble methods, AutoML, deep learning\n",
    "- **MLOps:** Model serving, CI/CD, containerization\n",
    "- **Ethics:** Fairness, accountability, transparency\n",
    "- **Domain Knowledge:** Finance, risk management, regulations\n",
    "\n",
    "### ğŸ“Š Project Artifacts:\n",
    "\n",
    "All your work is saved:\n",
    "- `data/processed/`: Cleaned datasets\n",
    "- `models/`: Trained models\n",
    "- `plots/`: All visualizations\n",
    "- `mlruns/`: Complete experiment history\n",
    "- Notebooks: Full workflow documentation\n",
    "\n",
    "### ğŸ™ Final Notes:\n",
    "\n",
    "Remember:\n",
    "- Machine learning is iterative\n",
    "- Domain expertise is invaluable\n",
    "- Ethics and fairness matter\n",
    "- Communication is crucial\n",
    "- Never stop learning!\n",
    "\n",
    "**Thank you for following this educational journey! ğŸ‰**\n",
    "\n",
    "---\n",
    "\n",
    "**Project by:** Shahul SHAIK\n",
    "**Date:** December 2025\n",
    "**Framework:** Scikit-learn, XGBoost, MLflow, SHAP\n",
    "**Dataset:** Home Credit Default Risk\n",
    "\n",
    "---\n",
    "\n",
    "For questions or improvements, refer to the project documentation!"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
